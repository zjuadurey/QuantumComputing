{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# This cell is added by sphinx-gallery\n# It can be customized to whatever you like\n%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Shadow Hamiltonian simulation\n\nShadow Hamiltonian simulation is a new approach (published last week) to\nquantum simulation on quantum computers. Despite its name, it has little\nto do with\n`classical shadows </demos/tutorial_diffable_shadows>`{.interpreted-text\nrole=\"doc\"}. In quantum simulation, the goal is typically to simulate\nthe time evolution of expectation values of $M$ observables $O_m,$ for\n$m=1,\\ldots ,M.$ The common approach is to evolve the wave function\n$|\\psi\\rangle$ and then measure the desired observables after the\nevolution.\n\nIn shadow Hamiltonian simulation, we instead directly encode the\nexpectation values in a proxy state --- the **shadow state** --- and\nevolve that state accordingly. Specifically for time evolution, we can\nwrite a shadow Schr\u00f6dinger equation that governs the dynamics of the\nshadow state.\n\n![](../_static/demo_thumbnails/opengraph_demo_thumbnails/OGthumbnail_shadow_hamiltonian_simulation.png){.align-center\nwidth=\"70.0%\"}\n\nThis is fundamentally different to the common approach. Foremost, the\ndimensionality of the shadow system no longer depends on the number of\nconstituents, $n,$ of the system. In fact, the underlying state can be\nmixed or even infinite-dimensional. Instead, the shadow system\\'s size\nis dependent on the number of observables $M$ that we want to measure.\nNote that there are conditions of completeness on the observables for\nthe shadow encoding to succeed, called [invariance property]{.title-ref}\nin. Further, since the expectation values are encoded in the amplitudes\nof states, we cannot directly measure them anymore, but need to resort\nto some form of state tomography. On the other hand, this gives us\nentirely new possibilities by letting us sample from the probability\ndistribution $p_m = |\\langle O_m \\rangle|^2$ and measure the absolute\nvalue of all observables simultaneously in the standard Z basis.\n\nIn this demo, we are going to introduce the basic concepts of shadow\nHamiltonian simulation alongside some easy-to-follow code snippets. We\nwill also see later how shadow Hamiltonian simulation comes down to\n`g-sim </demos/tutorial_liesim>`{.interpreted-text role=\"doc\"}, a\nLie-algebraic classical simulation tool, but run on a quantum computer\nwith some simplifications specifically due to considering Hamiltonian\nsimulation.\n\n## Shadow Hamiltonian simulation --- Definition\n\nIn common quantum Hamiltonian simulation, we evolve a state vector\n$|\\psi(t)\\rangle$ according to the Schr\u00f6dinger equation,\n\n$$\\frac{\\text{d}}{\\text{dt}} |\\psi(t)\\rangle = -i H |\\psi(t)\\rangle,$$\n\nby some Hamiltonian $H,$ and then compute expectation values of the\nevolved state through measurement. In shadow Hamiltonian simulation, we\nencode a set of expectation values in the amplitudes of a quantum state,\nand evolve those according to some shadow Schr\u00f6dinger equation.\n\nFor that, we first need to define the shadow state,\n\n$$\\begin{aligned}\n|\\rho\\rangle = \\frac{1}{\\sqrt{A}} \\begin{pmatrix} \\langle O_1 \\rangle \\\\ \\vdots \\\\ \\langle O_M \\rangle \\end{pmatrix},\n\\end{aligned}$$\n\nfor a set of operators $S = \\{O_m\\}$ and normalization constant\n$A = \\sum_m |\\langle O_m \\rangle|^2.$ This means that we can encode\nthese $M$ operator expectation values into $n_S$ qubits, as long as\n$2^{n_S} \\geq M.$ Note that $\\langle O_m \\rangle = \\text{tr}[O_m \\rho],$\nso we can have mixed or even infinite-dimensional states $\\rho.$\n\nThe shadow state evolves according to its shadow Schr\u00f6dinger equation,\n\n$$\\frac{\\text{d}}{\\text{dt}} |\\rho\\rangle = - i H_S |\\rho\\rangle.$$\n\nThe Hamiltonian matrix $H_S$ is given by the commutation relations\nbetween the system Hamiltonian $H$ and the operators in $S = \\{O_m\\},$\n\n$$[H, O_m] = - \\sum_{m'=1}^M \\left( H_S \\right)_{m m'} O_{m'}.$$\n\nLet us solve for the matrix elements $(H_S)_{m m'}.$ To do this, recall\nthat a vector $\\boldsymbol{v}$ can always be decomposed in an orthogonal\nbasis $\\boldsymbol{e}_j$ via\n$\\boldsymbol{v} = \\sum_j \\frac{\\langle \\boldsymbol{e}_j, \\boldsymbol{v}\\rangle}{||\\boldsymbol{e}_j||^2} \\boldsymbol{e}_j.$\nSince the operators under consideration are elements of the vector space\nof Hermitian operators, we can use this to compute $H_S.$\n\nIn particular, with the trace inner product, this amounts to\n\n$$[H, O_m] = \\sum_{m'=1}^M \\frac{\\text{tr}\\left( O_{m'} [H, O_m] \\right)}{|| O_{m'} ||^2} O_{m'},$$\n\nfrom which we can read off the matrix elements of $H_S,$ i.e.,\n\n$$(H_S)_{m m'} = -\\frac{\\text{tr}\\left( O_{m'} [H, O_m] \\right)}{|| O_{m'} ||^2}.$$\n\nNow, we can see that the operators $O_m$ need to be chosen such that all\npotentially new operators $\\mathcal{O} = [H, O_m]$, resulting from\ntaking the commutator between $H$ and $O_m,$ are decomposable in terms\nof $O_m$ again. In particular, the operators $O_m$ need to form a basis\nfor $\\{\\mathcal{O} | \\mathcal{O} = [H, O_m] \\}.$ Another way to say this\nis that $\\{O_m\\}$ need to contain all nested commutators\n$[[[H, O_m], O_m'], .. ],$ which is similar to\n`~pennylane.lie_closure`{.interpreted-text role=\"func\"} but weaker\nbecause it revolves around just $H.$ In the paper this is called the\n**invariance property**.\n\n::: note\n::: title\nNote\n:::\n\nTake for example $H = X$ and $S = \\{Y\\}$. Then $[H, Y] = iZ,$ so there\nis no linear combination of elements in $S$ that can decompose $[H, Y].$\nWe need to extend the list such that we have $S = \\{Y, Z\\}$. Now all\nresults from commutation, $[H, Y] = iZ$ and $[H, Z] = -iY,$ are\nsupported by $S.$ This is similar to the Lie closure that we discuss in\nour\n`intro to Lie algebras for quantum practitioners </demos/tutorial_liesim>`{.interpreted-text\nrole=\"doc\"}, but the requirements are not as strict because we only need\nsupport with respect to commentators with $H,$ and not among all\nelements in $S.$\n:::\n\n## How this relates to g-sim\n\nIn `g-sim </demos/tutorial_liesim>`{.interpreted-text role=\"doc\"} , we\nhave operators $\\{ g_i \\}$ that are generators or observables for a\nparametrized quantum circuit, e.g.\n$U(\\theta) = \\prod_\\ell \\exp(-i \\theta_\\ell g_\\ell)$ and\n$\\langle g_i \\rangle.$ For that, we are looking at the so-called\ndynamical Lie algebra (DLA) of the circuit,\n$\\mathfrak{g} = \\langle \\{ g_i \\} \\rangle_\\text{Lie} = \\{ g_1, .., g_{|\\mathfrak{g}|} \\},$\nas well as the adjoint representation\n$(-i \\text{ad}_{g_\\gamma})_{\\alpha \\beta} = f^\\gamma_{\\alpha \\beta},$\nwhere $f^\\gamma_{\\alpha \\beta}$ are the\n`~pennylane.structure_constants`{.interpreted-text role=\"func\"} of the\nDLA. They are computed via\n\n$$f^\\gamma_{\\alpha \\beta} = \\frac{\\text{tr}\\left(g_\\gamma [g_\\alpha, g_\\beta] \\right)}{||g_\\gamma||^2}.$$\n\nThe operators in $\\frak{g}$ can always be orthonormalized via the\n[Gram--Schmidt\nprocess](https://en.wikipedia.org/wiki/Gram%E2%80%93Schmidt_process), in\nwhich case we can drop the denominator. Further, by means of the cyclic\nproperty of the trace, we can rewrite this expression to obtain\n\n$$f^\\gamma_{\\alpha \\beta} = \\text{tr}\\left(g_\\beta [g_\\gamma, g_\\alpha] \\right).$$\n\nFrom this, we see how $H_S$ corresponds to the adjoint representation\n$i \\text{ad}_H$ (but we don\\'t require the full Lie algebra here, see\nbelow). For further details on the concept of the adjoint\nrepresentation, see our\n`demo on g-sim </demos/tutorial_liesim>`{.interpreted-text role=\"doc\"}\nthat makes extensive use of it.\n\nIn g-sim, we also evolve expectation vectors\n$(\\vec{g})_i = \\langle g_i \\rangle.$ In particular, the circuit of\nevolving a state according to $U(\\theta)$ and computing expectation\nvalues $\\langle g_i \\rangle$ then corresponds to evolving $\\vec{g}$ by\n$\\prod_\\ell \\exp(-i \\theta_\\ell \\text{ad}_{g_\\ell}).$\n\nShadow Hamiltonian simulation can thus be viewed as g-sim with a single,\nspecific gate $U(\\theta) = e^{-i \\theta H}$ and parameter $\\theta = t,$\nand run on a quantum computer.\n\nOne striking difference is that, because we only have one specific\n\\\"gate\\\", we do not need the full Lie closure of the operators whose\nexpectation values we want to compute. Instead, here it is sufficient to\nchoose $O_m$ such that they build up the full support for all\n$[H, O_m].$ This could potentially be a significant difference, as the\nLie closure in most cases leads to an exponentially large DLA, though\nthe scaling of the span of all $[H, O_m]$ is unclear at this point.\n\n## A simple example\n\nThe abstract concepts of shadow Hamiltonian simulation are best\nillustrated with a simple and concrete example. We are interested in\nsimulating the Hamiltonian evolution of\n\n$$H = X + Y$$\n\nafter a time $t = 1$ and computing the expectation values of\n$S = \\{X, Y, Z, I \\}.$ In the standard formulation, we simply evolve the\ninitial quantum state $|\\psi(0)\\rangle = |0\\rangle$ by $H$ in the\nfollowing way.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import pennylane as qml\nimport numpy as np\nfrom pennylane import X, Y, Z, I\n\ndev = qml.device(\"default.qubit\")\n\nS = [X(0), Y(0), Z(0), I(0)]\nH = X(0) + Y(0)\n\n@qml.qnode(dev)\ndef evolve(H, t):\n    qml.evolve(H, t)\n    return [qml.expval(Om) for Om in S]\n\nt = 1.\nO_t_standard = np.array(evolve(H, t))\nO_t_standard"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We evolved a $2^n = 2$ dimensional quantum state and performed $3$\nindependent (non-commuting) measurements.\n\nIn shadow Hamiltonian simulation, we encode $4$ expectation values in a\n$2^2 = 4$-dimensional quantum state, i.e., $n_S = 2.$\n\nFor this specific example, the number of operators is larger than the\nnumber of qubits, leading to a shadow system that is larger than the\noriginal system. This may or may not be a clever choice, but the point\nhere is just to illustrate the conceptual difference between both\napproaches. The authors in show various examples where the resulting\nshadow system is significantly smaller than the original system. It\nshould also be noted that having a smaller shadow system may not always\nbe its sole purpose, as there are conceptually new avenues one can\nexplore with shadow Hamiltonian simulation, such as sampling from the\ndistribution $p_m = |\\langle O_m \\rangle |^2.$\n\nLet us first construct the initial shadow state $\\boldsymbol{O}(t=0)$ by\ncomputing\n$\\langle O_m \\rangle_{t=0} = \\text{tr}\\left(O_m |\\psi(0)\\rangle \\langle \\psi(0)| \\right)$\nwith $|\\psi(0)\\rangle = |0\\rangle.$ The `pauli_rep` attribute of\nPennyLane operators returns a\n`~.pennylane.pauli.PauliSentence`{.interpreted-text role=\"class\"}\ninstance and lets us efficiently compute the trace, where we use the\ntrick that $|0 \\rangle \\langle 0| = (I + Z)/2.$\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "S_pauli = [op.pauli_rep for op in S]\n\nO_0 = np.zeros(len(S))\n\nfor m, Om in enumerate(S_pauli):\n    psi0 = (I(0) + Z(0)).pauli_rep\n\n    O_0[m] = (psi0 @ Om).trace()\n\n\nO_0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "There are a variety of methods to encode this vector in a qubit basis,\nbut we will just be using `~.pennylane.StatePrep`{.interpreted-text\nrole=\"class\"} later.\n\nWe now go on to construct the shadow Hamiltonian $H_S$ by computing the\nelements\n$(H_S)_{m m'} = \\frac{\\text{tr}\\left( O_{m'} [H, O_m] \\right)}{|| O_{m'} ||^2},$\nand we again make use of the\n`~.pennylane.pauli.PauliSentence.trace`{.interpreted-text role=\"meth\"}\nmethod.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "H_pauli = H.pauli_rep\n\nH_S = np.zeros((len(S), len(S)), dtype=complex)\n\nfor m, Om in enumerate(S_pauli):\n    com = H_pauli.commutator(Om)\n    for mt, Omt in enumerate(S_pauli):\n        # v = \u2211 (v \u00b7 e_j / ||e_j||^2) * e_j\n\n        value = (Omt @ com).trace()\n        value = value / (Omt @ Omt).trace()  \n        H_S[m,mt] = value\n\nH_S = -H_S # definition eq. (2) in [1]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In order for the shadow evolution to be unitary and implementable on a\nquantum computer, we need $H_S$ to be Hermitian.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "np.all(H_S == H_S.conj().T)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Knowing that, we can write the formal solution to the shadow Schr\u00f6dinger\nequation as\n\n$$\\boldsymbol{O}(t) = \\exp\\left(-i t H_S \\right) \\boldsymbol{O}(0).$$\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from scipy.linalg import expm\n\nO_t = expm(-1j * t * H_S) @ O_0\nO_t"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Up to this point, this is equivalent to\n`g-sim </demos/tutorial_liesim>`{.interpreted-text role=\"doc\"} if we\nwere doing classical simulation. Now, the main novelty for shadow\nHamiltonian simulation is to perform this on a quantum computer by\nencoding the expectation values of $\\langle O_m \\rangle$ in the\namplitude of a quantum state, and to translate $H_S$ accordingly.\n\nThis can be done by decomposing the numerical matrix $H_S$ into Pauli\noperators, which can, in turn, be implemented on a quantum computer.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "H_S_qubit = qml.pauli_decompose(H_S)\nH_S_qubit"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Using all these ingredients, we now are able to formulate the shadow\nHamiltonian simulation as a quantum algorithm. For the amplitude\nencoding, we need to make sure that the state is normalized. We use that\nnormalization factor to then later retrieve the correct result.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "A = np.linalg.norm(O_0)\n\n@qml.qnode(dev)\ndef shadow_evolve(H_S_qubit, O_0, t):\n    qml.StatePrep(O_0 / A, wires=range(2))\n    qml.evolve(H_S_qubit, t)\n    return qml.state()\n\nO_t_shadow = shadow_evolve(H_S_qubit, O_0, t) * A\n\nprint(O_t_standard)\nprint(O_t_shadow)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We see that the results of both approaches match.\n\nThe first result is coming from three independent measurements on a\nquantum computer after evolution with system Hamiltonian $H.$ This is\nconceptually very different from the second result where\n$\\boldsymbol{O}$ is encoded in the state of the shadow system (note the\n`qml.state()` return), which we evolved according to $H_S.$\n\nIn the first case, the measurement is directly obtained, however, in the\nshadow Hamiltonian simulation, we need to access the amplitudes of the\nunderlying state. This can be done naively with state tomography, but in\ninstances where we know that $\\langle O_m \\rangle \\geq 0,$ we can just\nsample bitstrings according to $p_m = |\\langle O_m\\rangle|^2.$ The\nability to sample from such a distribution\n$p_m = |\\langle O_m\\rangle|^2$ is a unique and new feature to shadow\nHamiltonian simulation.\n\nWe should also note that we made use of the abstract quantum\nsub-routines `~.pennylane.evolve`{.interpreted-text role=\"func\"} and\n`~.pennylane.StatePrep`{.interpreted-text role=\"class\"}, which each\nwarrant their specific implementation. For example,\n`~.pennylane.StatePrep`{.interpreted-text role=\"class\"} can be realized\nby `~MottonenStatePreparation`{.interpreted-text role=\"class\"} and\n`~.pennylane.evolve`{.interpreted-text role=\"func\"} can be realized by\n`TrotterProduct`{.interpreted-text role=\"class\"}, though that is not be\nthe focus of this demo.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Conclusion\n\nWe introduced the basic concepts of shadow Hamiltonian simulation and\nlearned how it fundamentally differs from the common approach to\nHamiltonian simulation.\n\nWe have seen how classical Hamiltonian simulation is tightly connected\nto g-sim, but run on a quantum computer. A significant difference comes\nfrom the fact that the authors in specifically look at Hamiltonian\nsimulation, $\\exp(-i t H),$ which allows us to just look at operators\n$O_m$ that support all commutators $[H, O_m],$ instead of the full Lie\nclosure. There may be some advantage to this feat, because Lie algebras\nin quantum computing typically scale exponentially. However, the scaling\nof such sets of operators is unclear at this point and needs further\ninvestigation.\n\nNote that even in the case of an exponentially sized set of operators,\nwe have --- at least in principle --- an exponentially large state\nvector to store the $M \\leq 2^{n_S}$ values. In the absolute worst case\nwe have $\\mathfrak{su}(2^n)$ with a dimension of $2^{2n}-1,$ so\n$n_S = 2n$ and thus it is just doubling the number of qubits.\n\nThe biggest potential to this new persepctive on Hamiltonian simulation\nmost likely lies in finding interesting applications like or that\nnaturally encode the problem and allow for efficient retrieval of all\nthe relevant information.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# References\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# About the author\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.17"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}